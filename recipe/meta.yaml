{% set name = "adversarial-robustness-toolbox" %}
{% set version = "1.15.1" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/adversarial-robustness-toolbox-{{ version }}.tar.gz
  sha256: bb11550743d311a71caae07ddb9af276d9f3e2a047312229573e2d40da7a2a94

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.6
  run:
    - matplotlib-base
    - numba >=0.53.1
    - numpy >=1.18.0
    - python >=3.6
    - pillow
    - scikit-learn >=0.22.2,<1.1.0
    - scipy >=1.4.1
    - setuptools
    - six
    - tqdm

test:
  imports:
    - art
    - art.attacks
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/Trusted-AI/adversarial-robustness-toolbox
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: Toolbox for adversarial machine learning.
  doc_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Documentation
  dev_url: https://github.com/Trusted-AI/adversarial-robustness-toolbox

extra:
  recipe-maintainers:
    - mxr-conda
